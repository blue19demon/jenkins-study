<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<include
		resource="org/springframework/boot/logging/logback/base.xml" />
	<!-- <appender name="LOGSTASH"
		class="net.logstash.logback.appender.LogstashTcpSocketAppender">
		<destination>127.0.0.1:4567</destination>
		<encoder charset="UTF-8"
			class="net.logstash.logback.encoder.LogstashEncoder" />
	</appender>
	<root level="INFO">
		<appender-ref ref="LOGSTASH" />
	</root> -->
	<property resource="application.yml" />
	<springProperty scope="context" name="APP_NAME"
		source="spring.application.name" />
	<!-- 开发环境1 -->
	<springProfile name="dev">
		<property name="log.path" value="logs/dev" />
		<!--输出到控制台 -->
		<appender name="console"
			class="ch.qos.logback.core.ConsoleAppender">
			 <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
		      <!--格式化输出,%d:日期;%thread:线程名;%-5level：级别,从左显示5个字符宽度;%msg:日志消息;%n:换行符-->
		      <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
		    </encoder>
		</appender>

		<!--输出到文件 -->
		<appender name="file"
			class="ch.qos.logback.core.rolling.RollingFileAppender">
			<rollingPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
				<fileNamePattern>${log.path}/${APP_NAME}-%d{yyyy-MM-dd}.%i.log
				</fileNamePattern>
				<maxHistory>10</maxHistory>
				<totalSizeCap>1GB</totalSizeCap>
				<maxFileSize>100MB</maxFileSize>
			</rollingPolicy>
			<encoder>
				<pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level
					%logger{36} - %msg%n</pattern>
			</encoder>
		</appender>
		<!--输出到kafka -->
		<appender name="KafkaAppender"
			class="com.github.danielwegener.logback.kafka.KafkaAppender">
			<encoder
				class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
				<layout class="net.logstash.logback.layout.LogstashLayout">
					<includeContext>false</includeContext>
					<includeCallerData>true</includeCallerData>
					<customFields>{"appname":"${APP_NAME}","env":"dev"}</customFields>
					<fieldNames
						class="net.logstash.logback.fieldnames.ShortenedFieldNames" />
				</layout>
				<charset>UTF-8</charset>
			</encoder>
			<!--kafka topic 需要与配置文件里面的topic一致 否则kafka会沉默并鄙视你 -->
			<topic>elkKafakaDev</topic>
			<keyingStrategy
				class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
			<deliveryStrategy
				class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
			<producerConfig>bootstrap.servers=127.0.0.1:9092</producerConfig>
		</appender>

		<!--你可能还需要加点这个玩意儿 -->
		<logger name="Application_ERROR">
			<appender-ref ref="KafkaAppender" />
		</logger>
	</springProfile>


	<!-- 开发环境2 -->
	<springProfile name="sit">
		<property name="log.path" value="logs/sit" />
		<!--输出到控制台 -->
		<appender name="console"
			class="ch.qos.logback.core.ConsoleAppender">
			<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
		      <!--格式化输出,%d:日期;%thread:线程名;%-5level：级别,从左显示5个字符宽度;%msg:日志消息;%n:换行符-->
		      <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
		    </encoder>
		</appender>

		<!--输出到文件 -->
		<appender name="file"
			class="ch.qos.logback.core.rolling.RollingFileAppender">
			<rollingPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
				<fileNamePattern>${log.path}/${APP_NAME}-%d{yyyy-MM-dd}.%i.log
				</fileNamePattern>
				<maxHistory>10</maxHistory>
				<totalSizeCap>1GB</totalSizeCap>
				<maxFileSize>100MB</maxFileSize>
			</rollingPolicy>
			<encoder>
				<pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level
					%logger{36} - %msg%n</pattern>
			</encoder>
		</appender>
		<!--输出到kafka -->
		<appender name="KafkaAppender"
			class="com.github.danielwegener.logback.kafka.KafkaAppender">
			<encoder
				class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
				<layout class="net.logstash.logback.layout.LogstashLayout">
					<includeContext>false</includeContext>
					<includeCallerData>true</includeCallerData>
					<customFields>{"appname":"${APP_NAME}","env":"sit"}</customFields>
					<fieldNames
						class="net.logstash.logback.fieldnames.ShortenedFieldNames" />
				</layout>
				<charset>UTF-8</charset>
			</encoder>
			<!--kafka topic 需要与配置文件里面的topic一致 否则kafka会沉默并鄙视你 -->
			<topic>elkKafakaSit</topic>
			<keyingStrategy
				class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
			<deliveryStrategy
				class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
			<producerConfig>bootstrap.servers=127.0.0.1:9092</producerConfig>
		</appender>

		<!--你可能还需要加点这个玩意儿 -->
		<logger name="Application_ERROR">
			<appender-ref ref="KafkaAppender" />
		</logger>
	</springProfile>


	<!-- 开发环境3 -->
	<springProfile name="uat">
		<property name="log.path" value="logs/uat" />
		<!--输出到控制台 -->
		<appender name="console"
			class="ch.qos.logback.core.ConsoleAppender">
			<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
		      <!--格式化输出,%d:日期;%thread:线程名;%-5level：级别,从左显示5个字符宽度;%msg:日志消息;%n:换行符-->
		      <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
		    </encoder>
		</appender>

		<!--输出到文件 -->
		<appender name="file"
			class="ch.qos.logback.core.rolling.RollingFileAppender">
			<rollingPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
				<fileNamePattern>${log.path}/${APP_NAME}-%d{yyyy-MM-dd}.%i.log
				</fileNamePattern>
				<maxHistory>10</maxHistory>
				<totalSizeCap>1GB</totalSizeCap>
				<maxFileSize>100MB</maxFileSize>
			</rollingPolicy>
			<encoder>
				<pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level
					%logger{36} - %msg%n</pattern>
			</encoder>
		</appender>
		<!--输出到kafka -->
		<appender name="KafkaAppender"
			class="com.github.danielwegener.logback.kafka.KafkaAppender">
			<encoder
				class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
				<layout class="net.logstash.logback.layout.LogstashLayout">
					<includeContext>false</includeContext>
					<includeCallerData>true</includeCallerData>
					<customFields>{"appname":"${APP_NAME}","env":"uat"}</customFields>
					<fieldNames
						class="net.logstash.logback.fieldnames.ShortenedFieldNames" />
				</layout>
				<charset>UTF-8</charset>
			</encoder>
			<!--kafka topic 需要与配置文件里面的topic一致 否则kafka会沉默并鄙视你 -->
			<topic>elkKafakaUat</topic>
			<keyingStrategy
				class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
			<deliveryStrategy
				class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
			<producerConfig>bootstrap.servers=127.0.0.1:9092</producerConfig>
		</appender>

		<!--你可能还需要加点这个玩意儿 -->
		<logger name="Application_ERROR">
			<appender-ref ref="KafkaAppender" />
		</logger>
	</springProfile>

	<!-- 生产环境 -->
	<springProfile name="prod">
		<property name="log.path" value="logs/prod" />
		<!--输出到控制台 -->
		<appender name="console"
			class="ch.qos.logback.core.ConsoleAppender">
			<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
		      <!--格式化输出,%d:日期;%thread:线程名;%-5level：级别,从左显示5个字符宽度;%msg:日志消息;%n:换行符-->
		      <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
		    </encoder>
		</appender>

		<!--输出到文件 -->
		<appender name="file"
			class="ch.qos.logback.core.rolling.RollingFileAppender">
			<rollingPolicy
				class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
				<fileNamePattern>${log.path}/${APP_NAME}-%d{yyyy-MM-dd}.%i.log
				</fileNamePattern>
				<maxHistory>10</maxHistory>
				<totalSizeCap>1GB</totalSizeCap>
				<maxFileSize>100MB</maxFileSize>
			</rollingPolicy>
			<encoder>
				<pattern>%d{HH:mm:ss.SSS} %contextName [%thread] %-5level
					%logger{36} - %msg%n</pattern>
			</encoder>
		</appender>
		<!--输出到kafka -->
		<appender name="KafkaAppender"
			class="com.github.danielwegener.logback.kafka.KafkaAppender">
			<encoder
				class="com.github.danielwegener.logback.kafka.encoding.LayoutKafkaMessageEncoder">
				<layout class="net.logstash.logback.layout.LogstashLayout">
					<includeContext>false</includeContext>
					<includeCallerData>true</includeCallerData>
					<customFields>{"appname":"${APP_NAME}","env":"prod"}</customFields>
					<fieldNames
						class="net.logstash.logback.fieldnames.ShortenedFieldNames" />
				</layout>
				<charset>UTF-8</charset>
			</encoder>
			<!--kafka topic 需要与配置文件里面的topic一致 否则kafka会沉默并鄙视你 -->
			<topic>elkKafakaProd</topic>
			<keyingStrategy
				class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
			<deliveryStrategy
				class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
			<producerConfig>bootstrap.servers=127.0.0.1:9092</producerConfig>
		</appender>

		<!--你可能还需要加点这个玩意儿 -->
		<logger name="Application_ERROR">
			<appender-ref ref="KafkaAppender" />
		</logger>
	</springProfile>

	<root level="info">
		<appender-ref ref="console" />
		<appender-ref ref="file" />
		<appender-ref ref="KafkaAppender" />
	</root>
</configuration>